# Language-Translation model-using-Transformer
A language translation model using Transformer

The transformer has been coded from scratch (from the most cited paper: **Attention is all you need**) to understand the underlying mechanisms of attention and other encoder-decoder related aspects of transfomer.

The HuggingFace Library is used for tokenizing the data into vocabulary. The dataset can be downloaded from the following: -

https://huggingface.co/datasets/Helsinki-NLP/opus_books

Feel Free to use your own subset in order to select your source and target languages for the translation task.

![image](https://github.com/user-attachments/assets/3c928721-94c4-441b-bd67-5560638f015b)

